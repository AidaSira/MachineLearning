<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Sypnosis</title>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}

pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h1>Sypnosis</h1>

<p>The goal of this project is to use data from accelerometers on different parts of the bosy of 6 participants to predict how well they are doing a physical activity. </p>

<p>The partipants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. Therefore, the data set consists of data from six different participants and the outcome is classified into five different categories, one category corresponds to doing the exercise correctly and four correspond to common mistakes. The main objective is to implement a classifier that correctly categorizes 20 samples provided as a testing set.</p>

<h1>Data processing</h1>

<p>The first step was loading the data</p>

<pre><code class="r">ml   &lt;- read.csv(&quot;pml-training.csv&quot;, header = T)
</code></pre>

<p>Once the data was loaded, I inspected it to understand its quality and identify possible improvements. There were several variables with mainly NA or no values. These variables were removed with the help of excel. Furthermore, since in the testing set there are only variables new_window equal to &#39;no&#39;, all &#39;yes&#39; rows were deleted.
You can also embed plots, for example:</p>

<pre><code class="r">ml   &lt;- read.csv(&quot;pml-training.csv&quot;, header = T)
ml2&lt;-ml[ml$new_window==&#39;no&#39;,]
</code></pre>

<h1>Model building</h1>

<p>The first step was to divide the training set into ttraining and testing set. The training is large enough to achieve a  high accuracy, and the cross validation set is also large enough to give a good indication of the out of sample error.</p>

<p>The training data set was split up into one portion (75%) for model building (14718 observations) and another portion (25%) for cross-validation (4904 observations). The cross validation technique used was random sampling.</p>

<p>Random forest has been the prediction algorithm used. </p>

<pre><code class="r">inTrain&lt;- createDataPartition(y=ml2$classe, p=0.75, list=FALSE) 
training&lt;-ml2[inTrain,] 
testing&lt;-ml2[-inTrain,]
rf&lt;- randomForest(formula = classe ~ ., data = training) 
</code></pre>

<pre><code>## Error: missing values in object
</code></pre>

<pre><code class="r">rf
</code></pre>

<pre><code>## 
## Call:
##  randomForest(formula = classe ~ ., data = training) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 6
## 
##         OOB estimate of  error rate: 0.01%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 4185    0    0    0    0   0.0000000
## B    0 2848    0    0    0   0.0000000
## C    0    1 2566    0    0   0.0003896
## D    0    0    0 2412    0   0.0000000
## E    0    0    0    0 2706   0.0000000
</code></pre>

<p>As we can see the expected sample error rate is 0.01%</p>

<h1>Model testing</h1>

<p>Once I had built the random forest, I needed to test it on the previously created testing set. As we can see the random forest had a high accuracy.
As we can see in the confussion matrix, we expect an accuracy of 100% with CI (99.92%- 100%). Therefore the estimated error with cross validation is 0 with confidence intervals of 0-0.08%</p>

<pre><code class="r">pred&lt;- predict(rf,testing)
confusionMatrix(pred,testing$classe)
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1367    0    0    0    0
##          B    0  929    0    0    0
##          C    0    0  838    0    0
##          D    0    0    0  786    0
##          E    0    0    0    0  882
## 
## Overall Statistics
##                                     
##                Accuracy : 1         
##                  95% CI : (0.999, 1)
##     No Information Rate : 0.285     
##     P-Value [Acc &gt; NIR] : &lt;2e-16    
##                                     
##                   Kappa : 1         
##  Mcnemar&#39;s Test P-Value : NA        
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             1.000    1.000    1.000    1.000    1.000
## Specificity             1.000    1.000    1.000    1.000    1.000
## Pos Pred Value          1.000    1.000    1.000    1.000    1.000
## Neg Pred Value          1.000    1.000    1.000    1.000    1.000
## Prevalence              0.285    0.193    0.175    0.164    0.184
## Detection Rate          0.285    0.193    0.175    0.164    0.184
## Detection Prevalence    0.285    0.193    0.175    0.164    0.184
## Balanced Accuracy       1.000    1.000    1.000    1.000    1.000
</code></pre>

<p>In the following plot I show the results on the testing set. As we can see, all observations in the testing set are predicted accurately.</p>

<pre><code class="r">matrix.table &lt;- as.data.frame(confusionMatrix$table)
ggplot(matrix.table, aes(x=Reference, y=Prediction,alpha = Freq)) +
  geom_tile(fill=&quot;white&quot;, color=&quot;black&quot;) +
  geom_text(aes(label=matrix.table$Freq)) +
  theme(legend.position=&quot;none&quot; )+
  xlab(&quot;Real Value&quot;) +  ylab(&quot;Prediction&quot;) 
</code></pre>

<p><img src="figure/unnamed-chunk-5.png" alt="plot of chunk unnamed-chunk-5"> </p>

<h1>Final comments</h1>

<p>The model used was a random forest algorithm using 500 trees. 
The random forest algorithm correctly identified 20 out of 20 test cases (100% accurate): B A B A A E D B A A B C B A E E A B B B</p>

</body>

</html>
